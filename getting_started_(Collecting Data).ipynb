{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1\n",
    "\n",
    "---\n",
    "\n",
    "## Web scraping and analysis\n",
    "\n",
    "This Jupyter notebook includes some code to get you started with web scraping. We will use a package called `BeautifulSoup` to collect the data from the web. Once you've collected your data and saved it into a local `.csv` file you should start with your analysis.\n",
    "\n",
    "### Scraping data from Skytrax\n",
    "\n",
    "If you visit [https://www.airlinequality.com] you can see that there is a lot of data there. For this task, we are only interested in reviews related to British Airways and the Airline itself.\n",
    "\n",
    "If you navigate to this link: [https://www.airlinequality.com/airline-reviews/british-airways] you will see this data. Now, we can use `Python` and `BeautifulSoup` to collect all the links to the reviews and then to collect the text data on each of the individual review links."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import requests "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 1\n",
      "   ---> 100 total reviews\n",
      "   ---> 101 total stars\n",
      "   ---> 100 total dates\n",
      "   ---> 100 total countries\n",
      "Scraping page 2\n",
      "   ---> 200 total reviews\n",
      "   ---> 202 total stars\n",
      "   ---> 200 total dates\n",
      "   ---> 200 total countries\n",
      "Scraping page 3\n",
      "   ---> 300 total reviews\n",
      "   ---> 303 total stars\n",
      "   ---> 300 total dates\n",
      "   ---> 300 total countries\n",
      "Scraping page 4\n",
      "   ---> 400 total reviews\n",
      "   ---> 404 total stars\n",
      "   ---> 400 total dates\n",
      "   ---> 400 total countries\n",
      "Scraping page 5\n",
      "   ---> 500 total reviews\n",
      "   ---> 505 total stars\n",
      "   ---> 500 total dates\n",
      "   ---> 500 total countries\n",
      "Scraping page 6\n",
      "   ---> 600 total reviews\n",
      "   ---> 606 total stars\n",
      "   ---> 600 total dates\n",
      "   ---> 600 total countries\n",
      "Scraping page 7\n",
      "   ---> 700 total reviews\n",
      "   ---> 707 total stars\n",
      "   ---> 700 total dates\n",
      "   ---> 700 total countries\n",
      "Scraping page 8\n",
      "   ---> 800 total reviews\n",
      "   ---> 808 total stars\n",
      "   ---> 800 total dates\n",
      "   ---> 800 total countries\n",
      "Scraping page 9\n",
      "   ---> 900 total reviews\n",
      "   ---> 909 total stars\n",
      "   ---> 900 total dates\n",
      "   ---> 900 total countries\n",
      "Scraping page 10\n",
      "   ---> 1000 total reviews\n",
      "   ---> 1010 total stars\n",
      "   ---> 1000 total dates\n",
      "   ---> 1000 total countries\n",
      "Scraping page 11\n",
      "   ---> 1100 total reviews\n",
      "   ---> 1111 total stars\n",
      "   ---> 1100 total dates\n",
      "   ---> 1100 total countries\n",
      "Scraping page 12\n",
      "   ---> 1200 total reviews\n",
      "   ---> 1212 total stars\n",
      "   ---> 1200 total dates\n",
      "   ---> 1200 total countries\n",
      "Scraping page 13\n",
      "   ---> 1300 total reviews\n",
      "   ---> 1313 total stars\n",
      "   ---> 1300 total dates\n",
      "   ---> 1300 total countries\n",
      "Scraping page 14\n",
      "   ---> 1400 total reviews\n",
      "   ---> 1414 total stars\n",
      "   ---> 1400 total dates\n",
      "   ---> 1400 total countries\n",
      "Scraping page 15\n",
      "   ---> 1500 total reviews\n",
      "   ---> 1515 total stars\n",
      "   ---> 1500 total dates\n",
      "   ---> 1500 total countries\n",
      "Scraping page 16\n",
      "   ---> 1600 total reviews\n",
      "   ---> 1616 total stars\n",
      "   ---> 1600 total dates\n",
      "   ---> 1600 total countries\n",
      "Scraping page 17\n",
      "   ---> 1700 total reviews\n",
      "   ---> 1717 total stars\n",
      "   ---> 1700 total dates\n",
      "   ---> 1700 total countries\n",
      "Scraping page 18\n",
      "   ---> 1800 total reviews\n",
      "   ---> 1818 total stars\n",
      "   ---> 1800 total dates\n",
      "   ---> 1800 total countries\n",
      "Scraping page 19\n",
      "   ---> 1900 total reviews\n",
      "   ---> 1919 total stars\n",
      "   ---> 1900 total dates\n",
      "   ---> 1900 total countries\n",
      "Scraping page 20\n",
      "   ---> 2000 total reviews\n",
      "   ---> 2020 total stars\n",
      "   ---> 2000 total dates\n",
      "   ---> 2000 total countries\n",
      "Scraping page 21\n",
      "   ---> 2100 total reviews\n",
      "   ---> 2121 total stars\n",
      "   ---> 2100 total dates\n",
      "   ---> 2100 total countries\n",
      "Scraping page 22\n",
      "   ---> 2200 total reviews\n",
      "   ---> 2222 total stars\n",
      "   ---> 2200 total dates\n",
      "   ---> 2200 total countries\n",
      "Scraping page 23\n",
      "   ---> 2300 total reviews\n",
      "   ---> 2323 total stars\n",
      "   ---> 2300 total dates\n",
      "   ---> 2300 total countries\n",
      "Scraping page 24\n",
      "   ---> 2400 total reviews\n",
      "   ---> 2424 total stars\n",
      "   ---> 2400 total dates\n",
      "   ---> 2400 total countries\n",
      "Scraping page 25\n",
      "   ---> 2500 total reviews\n",
      "   ---> 2525 total stars\n",
      "   ---> 2500 total dates\n",
      "   ---> 2500 total countries\n",
      "Scraping page 26\n",
      "   ---> 2600 total reviews\n",
      "   ---> 2626 total stars\n",
      "   ---> 2600 total dates\n",
      "   ---> 2600 total countries\n",
      "Scraping page 27\n",
      "   ---> 2700 total reviews\n",
      "   ---> 2727 total stars\n",
      "   ---> 2700 total dates\n",
      "   ---> 2700 total countries\n",
      "Scraping page 28\n",
      "   ---> 2800 total reviews\n",
      "   ---> 2828 total stars\n",
      "   ---> 2800 total dates\n",
      "   ---> 2800 total countries\n",
      "Scraping page 29\n",
      "   ---> 2900 total reviews\n",
      "   ---> 2929 total stars\n",
      "   ---> 2900 total dates\n",
      "   ---> 2900 total countries\n",
      "Scraping page 30\n",
      "   ---> 3000 total reviews\n",
      "   ---> 3030 total stars\n",
      "   ---> 3000 total dates\n",
      "   ---> 3000 total countries\n",
      "Scraping page 31\n",
      "   ---> 3100 total reviews\n",
      "   ---> 3131 total stars\n",
      "   ---> 3100 total dates\n",
      "   ---> 3100 total countries\n",
      "Scraping page 32\n",
      "   ---> 3200 total reviews\n",
      "   ---> 3232 total stars\n",
      "   ---> 3200 total dates\n",
      "   ---> 3200 total countries\n",
      "Scraping page 33\n",
      "   ---> 3300 total reviews\n",
      "   ---> 3333 total stars\n",
      "   ---> 3300 total dates\n",
      "   ---> 3300 total countries\n",
      "Scraping page 34\n",
      "   ---> 3400 total reviews\n",
      "   ---> 3434 total stars\n",
      "   ---> 3400 total dates\n",
      "   ---> 3400 total countries\n",
      "Scraping page 35\n",
      "   ---> 3500 total reviews\n",
      "   ---> 3535 total stars\n",
      "   ---> 3500 total dates\n",
      "   ---> 3500 total countries\n",
      "Scraping page 36\n",
      "   ---> 3600 total reviews\n",
      "   ---> 3600 total stars\n",
      "   ---> 3600 total dates\n",
      "   ---> 3600 total countries\n",
      "Maximum number of entries reached for all lists. Stopping scraping.\n",
      "Total reviews: 3600\n",
      "Total stars: 3600\n",
      "Total dates: 3600\n",
      "Total countries: 3600\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "base_url = \"https://www.airlinequality.com/airline-reviews/british-airways/\"\n",
    "pages = 38\n",
    "page_size = 100\n",
    "max_entries_per_list = 3600\n",
    "\n",
    "# Creating empty lists to collect all reviews, rating stars, date, and country\n",
    "reviews = []\n",
    "stars = []\n",
    "date = []\n",
    "country = []\n",
    "\n",
    "# Counters to keep track of the total number of entries for each list\n",
    "total_reviews = 0\n",
    "total_stars = 0\n",
    "total_dates = 0\n",
    "total_countries = 0\n",
    "\n",
    "for i in range(1, pages + 1):\n",
    "    print(f\"Scraping page {i}\")\n",
    "\n",
    "    # Create URL to collect links from paginated data\n",
    "    url = f\"{base_url}/page/{i}/?sortby=post_date%3ADesc&pagesize={page_size}\"\n",
    "\n",
    "    # Collect HTML data from this page\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # Parse content\n",
    "    content = response.content\n",
    "    parsed_content = BeautifulSoup(content, 'html.parser')\n",
    "\n",
    "    # Scraping reviews\n",
    "    for para in parsed_content.find_all(\"div\", {\"class\": \"text_content\"}):\n",
    "        if total_reviews < max_entries_per_list:\n",
    "            reviews.append(para.get_text())\n",
    "            total_reviews += 1\n",
    "\n",
    "    # Scraping star ratings\n",
    "    for para in parsed_content.find_all(\"div\", {\"class\": \"rating-10\"}):\n",
    "        if total_stars < max_entries_per_list:\n",
    "            star = para.span.get_text() if para.span else \"None\"\n",
    "            stars.append(star)\n",
    "            total_stars += 1\n",
    "\n",
    "    # Scraping dates\n",
    "    for para in parsed_content.find_all(\"time\"):\n",
    "        if total_dates < max_entries_per_list:\n",
    "            date.append(para.text)\n",
    "            total_dates += 1\n",
    "\n",
    "    # Scraping countries\n",
    "    for para in parsed_content.find_all(\"h3\"):\n",
    "        if total_countries < max_entries_per_list:\n",
    "            country.append(para.span.next_sibling.text.strip(\" ()\"))\n",
    "            total_countries += 1\n",
    "\n",
    "    print(f\"   ---> {total_reviews} total reviews\")\n",
    "    print(f\"   ---> {total_stars} total stars\")\n",
    "    print(f\"   ---> {total_dates} total dates\")\n",
    "    print(f\"   ---> {total_countries} total countries\")\n",
    "\n",
    "    # Check if any list has reached its maximum size\n",
    "    if total_reviews >= max_entries_per_list and \\\n",
    "       total_stars >= max_entries_per_list and \\\n",
    "       total_dates >= max_entries_per_list and \\\n",
    "       total_countries >= max_entries_per_list:\n",
    "        print(\"Maximum number of entries reached for all lists. Stopping scraping.\")\n",
    "        break\n",
    "\n",
    "# Truncate lists to ensure they contain a maximum of 3600 entries each\n",
    "reviews = reviews[:max_entries_per_list]\n",
    "stars = stars[:max_entries_per_list]\n",
    "date = date[:max_entries_per_list]\n",
    "country = country[:max_entries_per_list]\n",
    "\n",
    "print(f\"Total reviews: {len(reviews)}\")\n",
    "print(f\"Total stars: {len(stars)}\")\n",
    "print(f\"Total dates: {len(date)}\")\n",
    "print(f\"Total countries: {len(country)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>stars</th>\n",
       "      <th>date</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3600</td>\n",
       "      <td>3600</td>\n",
       "      <td>3600</td>\n",
       "      <td>3600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>3589</td>\n",
       "      <td>12</td>\n",
       "      <td>1824</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>London Heathrow to Miami on one of British Air...</td>\n",
       "      <td>1</td>\n",
       "      <td>19th January 2015</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>2</td>\n",
       "      <td>867</td>\n",
       "      <td>26</td>\n",
       "      <td>2247</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  reviews stars  \\\n",
       "count                                                3600  3600   \n",
       "unique                                               3589    12   \n",
       "top     London Heathrow to Miami on one of British Air...     1   \n",
       "freq                                                    2   867   \n",
       "\n",
       "                     date         country  \n",
       "count                3600            3600  \n",
       "unique               1824              71  \n",
       "top     19th January 2015  United Kingdom  \n",
       "freq                   26            2247  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "df[\"reviews\"] = reviews\n",
    "df[\"stars\"] = stars\n",
    "df[\"date\"] = date\n",
    "df[\"country\"] = country\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>stars</th>\n",
       "      <th>date</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>✅ Trip Verified |  This is the first time I ha...</td>\n",
       "      <td>\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t5</td>\n",
       "      <td>2nd April 2024</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>✅ Trip Verified |  Flew business class from Do...</td>\n",
       "      <td>3</td>\n",
       "      <td>2nd April 2024</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>✅ Trip Verified |  Starting off at Heathrow Te...</td>\n",
       "      <td>4</td>\n",
       "      <td>28th March 2024</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Not Verified |  We have flown this route with ...</td>\n",
       "      <td>8</td>\n",
       "      <td>28th March 2024</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>✅ Trip Verified | A last minute business trip ...</td>\n",
       "      <td>1</td>\n",
       "      <td>26th March 2024</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             reviews  \\\n",
       "0  ✅ Trip Verified |  This is the first time I ha...   \n",
       "1  ✅ Trip Verified |  Flew business class from Do...   \n",
       "2  ✅ Trip Verified |  Starting off at Heathrow Te...   \n",
       "3  Not Verified |  We have flown this route with ...   \n",
       "4  ✅ Trip Verified | A last minute business trip ...   \n",
       "\n",
       "                           stars             date         country  \n",
       "0  \\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t5   2nd April 2024  United Kingdom  \n",
       "1                              3   2nd April 2024  United Kingdom  \n",
       "2                              4  28th March 2024  United Kingdom  \n",
       "3                              8  28th March 2024  United Kingdom  \n",
       "4                              1  26th March 2024  United Kingdom  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"C:/Users/vatsa/Downloads/British-Airways-reviews-analysis/Data/BA_Data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations! Now you have your dataset for this task! The loops above collected 1000 reviews by iterating through the paginated pages on the website. However, if you want to collect more data, try increasing the number of pages!\n",
    "\n",
    " The next thing that you should do is clean this data to remove any unnecessary text from each of the rows. For example, \"✅ Trip Verified\" can be removed from each row if it exists, as it's not relevant to what we want to investigate."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "4f7924c4c56b083e0e50eadfe7ef592a7a8ef70df33a0047f82280e6be1afe15"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
